{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_names = [f.stem for f in Path(\"results\").iterdir()]\n",
    "pred_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Model Comparison\n",
    "\n",
    "Choose one or more of `pred_names` list above for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_preds = [\"qr_preds22\", \"deepensemble_pred\"]\n",
    "\n",
    "def read_files(names: list[str], folder: str) -> pd.DataFrame:\n",
    "    res_list = []\n",
    "    for name in names:\n",
    "        res = pd.read_csv(f\"{folder}/{name}.csv\")\n",
    "        res[\"pred_name\"] = name\n",
    "        res_list.append(res)\n",
    "    return pd.concat(res_list, ignore_index=True)\n",
    "\n",
    "res = read_files(use_preds, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=120)\n",
    "sns.pointplot(\n",
    "    data=res.query(\"eval_mode == 'multi'\"),\n",
    "    x=\"norm_score\",\n",
    "    y=\"variable\",\n",
    "    hue=\"pred_name\",\n",
    "    orient=\"h\",\n",
    "    palette=\"muted\",\n",
    "    dodge=True,\n",
    "    ax=ax,\n",
    "    linestyles=\"--\",\n",
    "    errorbar=\"ci\",\n",
    "    order=[\"theta\", \"theta_d\", \"x\", \"x_d\"]\n",
    ")\n",
    "ax.set_title(\"Multi-Step Evaluation\")\n",
    "plt.show()\n",
    "#fig.savefig(\"deepensemble_multi_step.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=120)\n",
    "sns.pointplot(\n",
    "    data=res.query(\"eval_mode == 'single'\"),\n",
    "    x=\"norm_score\",\n",
    "    y=\"variable\",\n",
    "    hue=\"pred_name\",\n",
    "    orient=\"h\",\n",
    "    palette=\"muted\",\n",
    "    dodge=True,\n",
    "    ax=ax,\n",
    "    linestyles=\"--\",\n",
    "    errorbar=\"ci\",\n",
    "    order=[\"theta\", \"theta_d\", \"x\", \"x_d\"]\n",
    ")\n",
    "ax.set_title(\"Single-Step Evaluation\")\n",
    "plt.show()\n",
    "#fig.savefig(\"deepensemble_single_step.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Breakdown\n",
    "\n",
    "Only models whose evaluations are saved in the `full_results` folder can be evaluated here. These are shown in the output of the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred_names = [f.stem for f in Path(\"full_results\").iterdir()]\n",
    "full_pred_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_preds = use_preds\n",
    "\n",
    "res_full = read_files(use_full_preds, \"full_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.FacetGrid(res_full.query(\"eval_mode == 'multi'\"), row=\"variable\", col=\"noise\", aspect=1.5, margin_titles=True, sharex=False)\n",
    "g.map_dataframe(sns.barplot, x=\"norm_score\", y=\"name\", hue=\"pred_name\", orient=\"h\", palette=\"muted\")\n",
    "g.fig.suptitle(\"Single Predictions\")\n",
    "g.fig.tight_layout()\n",
    "g.add_legend()\n",
    "plt.show()\n",
    "#g.savefig(\"deepensemble_multi_step_full.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals from a single Model\n",
    "\n",
    "This section is for inspecting the predictions themselves, especially multi-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_name = \"qr_preds22\"\n",
    "preds = pd.read_csv(f\"predictions/{pred_name}.csv\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Single Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variable = \"theta\"\n",
    "if variable == \"theta\":\n",
    "    nice_var = f\"$\\\\{variable}$\"\n",
    "else:\n",
    "    nice_var = \"x\"\n",
    "noise = \"det\"\n",
    "name = \"val\"\n",
    "eval_mode = \"multi\"\n",
    "start_row = 0\n",
    "nrows = 1000\n",
    "\n",
    "# Helper Function\n",
    "def qdf(df, vars):\n",
    "    qstr = \" & \".join(f\"{var} == @{var}\" for var in vars)\n",
    "    return df.query(qstr)\n",
    "\n",
    "# Filtered data\n",
    "tmp = qdf(preds, [\"name\", \"variable\", \"noise\", \"eval_mode\"]).set_index(\"t\").iloc[start_row:nrows]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "for i, lev in enumerate([95, 80, 50]):\n",
    "    ax.fill_between(\n",
    "        tmp.index,\n",
    "        y1=tmp[f\"lower_{lev}\"],\n",
    "        y2=tmp[f\"upper_{lev}\"],\n",
    "        color=str(0.9 - 0.15 * (i + 1)),\n",
    "        label=\"\",\n",
    "    )\n",
    "tmp[[\"actual\"]].plot(ax=ax)\n",
    "ax.set_ylabel(nice_var)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all Trajectories from one Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice plot\n",
    "noise = \"high_noise\"\n",
    "name = \"test\"\n",
    "eval_mode = \"multi\"\n",
    "nrows = 10000  # seconds times 100\n",
    "\n",
    "# Filtered data\n",
    "df_filt = qdf(preds, [\"noise\", \"name\", \"eval_mode\"]).set_index(\"t\")\n",
    "\n",
    "name_lookup = {\n",
    "    \"det\": \"No Noise\",\n",
    "    \"low_noise\": \"0.1 Gaussian Noise\",\n",
    "    \"high_noise\": \"0.5 Gaussian Noise\",\n",
    "}\n",
    "data_lookup = {\n",
    "    \"train\": \"Training Data\",\n",
    "    \"valid\": \"Extending Trajectories\",\n",
    "    \"val\": \"Extending Trajectories\",\n",
    "    \"test\": \"New Starting Position and Control Policy\",\n",
    "}\n",
    "var_lookup = {\n",
    "    \"theta\": r\"$\\theta$\",\n",
    "    \"theta_d\": r\"$\\dot{\\theta}$\",\n",
    "    \"x\": r\"$x$\",\n",
    "    \"x_d\": r\"$\\dot{x}$\",\n",
    "}\n",
    "nice_name = \", \".join([pred_name, name_lookup[noise], data_lookup[name]])\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(10, 12))\n",
    "for var, ax in zip(var_lookup, axes):\n",
    "    tmp = df_filt[df_filt.variable == var].iloc[:nrows]\n",
    "    for i, lev in enumerate([95, 80, 50]):\n",
    "        ax.fill_between(\n",
    "            tmp.index,\n",
    "            y1=tmp[f\"lower_{lev}\"],\n",
    "            y2=tmp[f\"upper_{lev}\"],\n",
    "            color=str(0.9 - 0.15 * (i + 1)),\n",
    "            label=\"\",\n",
    "        )\n",
    "    tmp[[\"actual\"]].plot(ax=ax)\n",
    "    ax.set_ylabel(var_lookup[var], rotation=0)\n",
    "fig.suptitle(nice_name, fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice plot\n",
    "noise = \"det\"\n",
    "name = \"test\"\n",
    "eval_mode = \"multi\"\n",
    "nrows = 10000  # seconds times 100\n",
    "\n",
    "# Filtered data\n",
    "df_filt = qdf(preds, [\"noise\", \"eval_mode\"]).set_index(\"t\")\n",
    "# df_filt = qdf(preds, [\"noise\", \"name\", \"eval_mode\"]).set_index(\"t\")\n",
    "\n",
    "name_lookup = {\n",
    "    \"det\": \"No Noise\",\n",
    "    \"low_noise\": \"0.1 Gaussian Noise\",\n",
    "    \"high_noise\": \"0.5 Gaussian Noise\",\n",
    "}\n",
    "data_lookup = {\n",
    "    \"train\": \"Training Data\",\n",
    "    # \"valid\": \"Extending Trajectories\",\n",
    "    \"val\": \"Extending Trajectories\",\n",
    "    \"test\": \"New Starting Position and Control Policy\",\n",
    "}\n",
    "var_lookup = {\n",
    "    \"theta\": r\"$\\theta$\",\n",
    "    # \"theta_d\": r\"$\\dot{\\theta}$\",\n",
    "    \"theta_d\": r\"$\\frac{d\\theta}{dt}$\",\n",
    "    \"x\": r\"$x$\",\n",
    "    \"x_d\": r\"$\\frac{dx}{dt}$\",\n",
    "}\n",
    "nice_name = \", \".join([pred_name, name_lookup[noise]])\n",
    "nice_name = \", \".join([\"Gradient Boosting\", name_lookup[noise]])\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 12))\n",
    "for j, data_name in enumerate(data_lookup):\n",
    "    for vi, var in enumerate(var_lookup):\n",
    "        ax = axes[vi, j]\n",
    "        tmp = df_filt[(df_filt.variable == var) & (df_filt.name == data_name)].iloc[:nrows]\n",
    "        for i, lev in enumerate([95, 80, 50]):\n",
    "            ax.fill_between(\n",
    "                tmp.index,\n",
    "                y1=tmp[f\"lower_{lev}\"],\n",
    "                y2=tmp[f\"upper_{lev}\"],\n",
    "                color=str(0.9 - 0.15 * (i + 1)),\n",
    "                label=f\"{lev}% Interval\",\n",
    "            )\n",
    "        tmp[[\"actual\"]].plot(ax=ax)\n",
    "        \n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.legend([])\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(var_lookup[var], rotation=0, fontsize=20)\n",
    "        if vi == 0:\n",
    "            ax.set_title(data_lookup[data_name], fontsize=20)\n",
    "        if vi == 3:\n",
    "            ax.set_xlabel(\"Time (seconds)\", fontsize=16)\n",
    "fig.suptitle(nice_name, fontsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels[-1] = \"Actual\"\n",
    "lgd = ax.legend(reversed(handles), reversed(labels), loc='right', bbox_to_anchor=(1.125, 0.5), fontsize=20, bbox_transform=fig.transFigure)\n",
    "title = fig.suptitle(nice_name, fontsize=20)\n",
    "# plt.show()\n",
    "fig.savefig(\"Performance.png\", bbox_inches=\"tight\", bbox_extra_artists=(lgd,title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import eval_preds\n",
    "\n",
    "\n",
    "# Nice plot\n",
    "noise = \"det\"\n",
    "name = \"test\"\n",
    "eval_mode = \"multi\"\n",
    "nrows = 10000  # seconds times 100\n",
    "\n",
    "# Filtered data\n",
    "df_filt = qdf(preds, [\"noise\", \"eval_mode\"]).set_index(\"t\")\n",
    "# df_filt = qdf(preds, [\"noise\", \"name\", \"eval_mode\"]).set_index(\"t\")\n",
    "\n",
    "name_lookup = {\n",
    "    \"det\": \"No Noise\",\n",
    "    \"low_noise\": \"0.1 Gaussian Noise\",\n",
    "    \"high_noise\": \"0.5 Gaussian Noise\",\n",
    "}\n",
    "data_lookup = {\n",
    "    \"train\": \"Training Data\",\n",
    "    # \"valid\": \"Extending Trajectories\",\n",
    "    \"val\": \"Extending Trajectories\",\n",
    "    \"test\": \"New Starting Position and Control Policy\",\n",
    "}\n",
    "var_lookup = {\n",
    "    \"theta\": r\"$\\theta$\",\n",
    "    # \"theta_d\": r\"$\\dot{\\theta}$\",\n",
    "    \"theta_d\": r\"$\\frac{d\\theta}{dt}$\",\n",
    "    \"x\": r\"$x$\",\n",
    "    \"x_d\": r\"$\\frac{dx}{dt}$\",\n",
    "}\n",
    "nice_name = \", \".join([\"Interval Scores\", \"Gradient Boosting\", name_lookup[noise]])\n",
    "# nice_name = \", \".join([pred_name, name_lookup[noise], data_lookup[name]])\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 12))\n",
    "for j, data_name in enumerate(data_lookup):\n",
    "    for vi, var in enumerate(var_lookup):\n",
    "        ax = axes[vi, j]\n",
    "        tmp = df_filt[(df_filt.variable == var) & (df_filt.name == data_name)].iloc[:nrows].reset_index()\n",
    "        tmp = eval_preds(tmp)\n",
    "\n",
    "        tmp.pivot_table(index=\"t\", columns=\"interval\", values=\"norm_score\").plot(ax=ax)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.legend([])\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(var_lookup[var], rotation=0, fontsize=20)\n",
    "        if vi == 0:\n",
    "            ax.set_title(data_lookup[data_name], fontsize=20)\n",
    "        if vi == 3:\n",
    "            ax.set_xlabel(\"Time (seconds)\", fontsize=16)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = [f\"{val}% Interval Score\" for val in labels]\n",
    "# labels[-1] = \"Actual\"\n",
    "# fig.tight_layout()\n",
    "# fig.tight_layout(rect=[0,0,0.75, 1])\n",
    "# lgd = fig.legend(reversed(handles), reversed(labels), loc=\"outside right center\", fontsize=20)\n",
    "lgd = ax.legend(reversed(handles), reversed(labels), loc='right', bbox_to_anchor=(1.125, 0.5), fontsize=20, bbox_transform=fig.transFigure)\n",
    "title = fig.suptitle(nice_name, fontsize=20)\n",
    "# plt.show()\n",
    "fig.savefig(\"winkler.png\", bbox_inches=\"tight\", bbox_extra_artists=(lgd,title))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ar_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
